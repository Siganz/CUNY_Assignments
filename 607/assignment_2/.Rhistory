true_positive= tp,
false_positive = fp,
true_negative = tn,
false_negative = fn,
accuracy = accuracy(tp, fp, tn, fn),
precision = precision(tp, fp),
recall = recall(tp, fn),
f1 = f1(tp, fp, fn)
)
tib |>
mutate(
across(c(accuracy, precision, recall, f1), round, digits = 2)
)
}
p <- threshold_prediction(df, t)
p
confusion_plot <- function(x) {
cm <- tibble(
Actual = c("Positive","Positive","Negative","Negative"),
Pred   = c("Positive","Negative","Positive","Negative"),
n = c(
x$true_positive,
x$false_negative,
x$false_positive,
x$true_negative
)
)
ggplot(cm, aes(x = Pred, y = Actual, fill = n)) +
geom_tile() +
geom_text(aes(label = n), color = "white", size = 6) +
scale_fill_gradient(low = "grey70", high = "steelblue") +
labs(
title = "Confusion Matrix",
subtitle = sprintf("Threshold %.1f", t),
x = "Predicted",
y = "Actual"
) +
theme_minimal() +
theme(
plot.title = element_text(hjust = 0.5),
plot.subtitle = element_text(hjust = 0.5)
)
}
t <- 0.2
m <- threshold_prediction(df, t)
m
confusion_plot(m)
t <- 0.5
m <- threshold_prediction(df, t)
m
confusion_plot(m)
t <- 0.8
m <- threshold_prediction(df, t)
m
confusion_plot(m)
evaluate_threshold <- function(df, t) {
m <- threshold_prediction(df, t)
print(m)
confusion_plot(m)
}
evaluate_threshold <- function(df, threshold) {
m <- threshold_prediction(df, threshold)
print(m)
confusion_plot(m)
}
threshold <- 0.2
evaluate_threshold(df, threshold)
library(tidyverse)
df_raw <- read.csv(
'https://raw.githubusercontent.com/acatlin/data/refs/heads/master/penguin_predictions.csv'
)
glimpse(df_raw)
temp <- df_raw |>
count(sex) |>
mutate(percent = round(((n / sum(n))*100), 0))
temp
glimpse(df_raw)
df <- df_raw
df <- df |>
count(sex) |>
mutate(percent = round(((n / sum(n))*100), 0))
df
null_error_rate <- min(df$n) / sum(df$n)
sprintf("The null error rate is %.02f",(null_error_rate))
ggplot(df, aes(x = sex, y = n, fill = sex)) +
geom_col() +
labs(
title = "Distribution of Sex",
subtitle = "The count of each sex for the study.",
x = "Sex",
y = "Count"
)
df <- df_raw |>
rename(
pred_female = .pred_female,
pred_class = .pred_class,
truth = sex
) |>
mutate(truth_bool = truth == "male")
glimpse(df)
threshold_prediction <- function(df_pred, t) {
pred  <- df_pred$pred_female >= t
reality <- df_pred$truth_bool
tp <-   sum(pred & reality)
fp <-   sum(pred & !reality)
tn <-   sum(!pred & !reality)
fn <-   sum(!pred & reality)
tibble(
threshold = t,
true_positive= tp,
false_positive = fp,
true_negative = tn,
false_negative = fn
)
}
threshold = 1
# run threshold_prediction
p <- threshold_prediction(df, t)
p
accuracy <- function(tp, fp, tn, fn){(tp + tn) / (tp + fp + tn + fn)}
precision <- function(tp, fp){tp / (tp + fp)}
recall <- function(tp, fn){tp / (tp + fn)}
f1  <- function(tp, fp, fn){
p <- precision(tp, fp)
r <- recall(tp, fn)
2 * (p * r) / (p + r)
}
threshold_prediction <- function(df_pred, threshold) {
pred  <- df_pred$pred_female >= threshold
reality <- df_pred$truth_bool
tp <-   sum(pred & reality)
fp <-   sum(pred & !reality)
tn <-   sum(!pred & !reality)
fn <-   sum(!pred & reality)
tib <- tibble(
threshold,
true_positive= tp,
false_positive = fp,
true_negative = tn,
false_negative = fn,
accuracy = accuracy(tp, fp, tn, fn),
precision = precision(tp, fp),
recall = recall(tp, fn),
f1 = f1(tp, fp, fn)
)
tib |>
mutate(
across(c(accuracy, precision, recall, f1), round, digits = 2)
)
}
p <- threshold_prediction(df, t)
p
confusion_plot <- function(x) {
cm <- tibble(
Actual = c("Positive","Positive","Negative","Negative"),
Pred   = c("Positive","Negative","Positive","Negative"),
n = c(
x$true_positive,
x$false_negative,
x$false_positive,
x$true_negative
)
)
ggplot(cm, aes(x = Pred, y = Actual, fill = n)) +
geom_tile() +
geom_text(aes(label = n), color = "white", size = 6) +
scale_fill_gradient(low = "grey70", high = "steelblue") +
labs(
title = "Confusion Matrix",
subtitle = sprintf("Threshold %.1f", t),
x = "Predicted",
y = "Actual"
) +
theme_minimal() +
theme(
plot.title = element_text(hjust = 0.5),
plot.subtitle = element_text(hjust = 0.5)
)
}
evaluate_threshold <- function(df, threshold) {
m <- threshold_prediction(df, threshold)
print(m)
confusion_plot(m)
}
threshold <- 0.2
evaluate_threshold(df, threshold)
threshold <- 0.5
evaluate_threshold(df, threshold)
threshold <- 0.8
mevaluate_threshold(df, threshold)
threshold <- 0.8
evaluate_threshold(df, threshold)
threshold_prediction <- function(df_pred, threshold) {
pred  <- df_pred$pred_female >= threshold
reality <- df_pred$truth_bool
tp <-   sum(pred & reality)
fp <-   sum(pred & !reality)
tn <-   sum(!pred & !reality)
fn <-   sum(!pred & reality)
tibble(
threshold = t,
true_positive= tp,
false_positive = fp,
true_negative = tn,
false_negative = fn
)
}
df <- df_raw |>
rename(
pred_female = .pred_female,
pred_class = .pred_class,
truth = sex
) |>
mutate(truth_bool = truth == "male")
glimpse(df)
threshold_prediction <- function(df_pred, threshold) {
pred  <- df_pred$pred_female >= threshold
reality <- df_pred$truth_bool
tp <-   sum(pred & reality)
fp <-   sum(pred & !reality)
tn <-   sum(!pred & !reality)
fn <-   sum(!pred & reality)
tibble(
threshold = t,
true_positive= tp,
false_positive = fp,
true_negative = tn,
false_negative = fn
)
}
threshold = 1
# run threshold_prediction
p <- threshold_prediction(df, t)
p
library(tidyverse)
df_raw <- read.csv(
'https://raw.githubusercontent.com/acatlin/data/refs/heads/master/penguin_predictions.csv'
)
glimpse(df_raw)
temp <- df_raw |>
count(sex) |>
mutate(percent = round(((n / sum(n))*100), 0))
temp
glimpse(df_raw)
df <- df_raw
df <- df |>
count(sex) |>
mutate(percent = round(((n / sum(n))*100), 0))
df
null_error_rate <- min(df$n) / sum(df$n)
sprintf("The null error rate is %.02f",(null_error_rate))
ggplot(df, aes(x = sex, y = n, fill = sex)) +
geom_col() +
labs(
title = "Distribution of Sex",
subtitle = "The count of each sex for the study.",
x = "Sex",
y = "Count"
)
df <- df_raw |>
rename(
pred_female = .pred_female,
pred_class = .pred_class,
truth = sex
) |>
mutate(truth_bool = truth == "male")
glimpse(df)
df_raw <- read.csv(
'https://raw.githubusercontent.com/acatlin/data/refs/heads/master/penguin_predictions.csv'
)
glimpse(df_raw)
threshold_prediction <- function(df_pred, threshold) {
pred  <- df_pred$pred_female >= threshold
reality <- df_pred$truth_bool
tp <-   sum(pred & reality)
fp <-   sum(pred & !reality)
tn <-   sum(!pred & !reality)
fn <-   sum(!pred & reality)
tibble(
threshold = threshold,
true_positive= tp,
false_positive = fp,
true_negative = tn,
false_negative = fn
)
}
threshold = 1
# run threshold_prediction
p <- threshold_prediction(df, t)
p
library(tidyverse)
df_raw <- read.csv(
'https://raw.githubusercontent.com/acatlin/data/refs/heads/master/penguin_predictions.csv'
)
glimpse(df_raw)
temp <- df_raw |>
count(sex) |>
mutate(percent = round(((n / sum(n))*100), 0))
temp
glimpse(df_raw)
df <- df_raw
df <- df |>
count(sex) |>
mutate(percent = round(((n / sum(n))*100), 0))
df
null_error_rate <- min(df$n) / sum(df$n)
sprintf("The null error rate is %.02f",(null_error_rate))
ggplot(df, aes(x = sex, y = n, fill = sex)) +
geom_col() +
labs(
title = "Distribution of Sex",
subtitle = "The count of each sex for the study.",
x = "Sex",
y = "Count"
)
df <- df_raw |>
rename(
pred_female = .pred_female,
pred_class = .pred_class,
truth = sex
) |>
mutate(truth_bool = truth == "female")
glimpse(df)
threshold_prediction <- function(df_pred, threshold) {
pred  <- df_pred$pred_female >= threshold
reality <- df_pred$truth_bool
tp <-   sum(pred & reality)
fp <-   sum(pred & !reality)
tn <-   sum(!pred & !reality)
fn <-   sum(!pred & reality)
tibble(
threshold = threshold,
true_positive= tp,
false_positive = fp,
true_negative = tn,
false_negative = fn
)
}
threshold = 1
# run threshold_prediction
p <- threshold_prediction(df, t)
p
accuracy <- function(tp, fp, tn, fn){(tp + tn) / (tp + fp + tn + fn)}
precision <- function(tp, fp){tp / (tp + fp)}
recall <- function(tp, fn){tp / (tp + fn)}
f1  <- function(tp, fp, fn){
p <- precision(tp, fp)
r <- recall(tp, fn)
2 * (p * r) / (p + r)
}
threshold_prediction <- function(df_pred, threshold) {
pred  <- df_pred$pred_female >= threshold
reality <- df_pred$truth_bool
tp <-   sum(pred & reality)
fp <-   sum(pred & !reality)
tn <-   sum(!pred & !reality)
fn <-   sum(!pred & reality)
tib <- tibble(
threshold,
true_positive= tp,
false_positive = fp,
true_negative = tn,
false_negative = fn,
accuracy = accuracy(tp, fp, tn, fn),
precision = precision(tp, fp),
recall = recall(tp, fn),
f1 = f1(tp, fp, fn)
)
tib |>
mutate(
across(c(accuracy, precision, recall, f1), round, digits = 2)
)
}
p <- threshold_prediction(df, t)
p
confusion_plot <- function(x) {
cm <- tibble(
Actual = c("Positive","Positive","Negative","Negative"),
Pred   = c("Positive","Negative","Positive","Negative"),
n = c(
x$true_positive,
x$false_negative,
x$false_positive,
x$true_negative
)
)
ggplot(cm, aes(x = Pred, y = Actual, fill = n)) +
geom_tile() +
geom_text(aes(label = n), color = "white", size = 6) +
scale_fill_gradient(low = "grey70", high = "steelblue") +
labs(
title = "Confusion Matrix",
subtitle = sprintf("Threshold %.1f", t),
x = "Predicted",
y = "Actual"
) +
theme_minimal() +
theme(
plot.title = element_text(hjust = 0.5),
plot.subtitle = element_text(hjust = 0.5)
)
}
evaluate_threshold <- function(df, threshold) {
m <- threshold_prediction(df, threshold)
print(m)
confusion_plot(m)
}
threshold <- 0.2
evaluate_threshold(df, threshold)
threshold <- 0.5
evaluate_threshold(df, threshold)
threshold <- 0.8
evaluate_threshold(df, threshold)
df |>
ggplot(
aes(x = truth)
) +
geom_bar
df |>
ggplot(
aes(x = truth)
) +
geom_bar()
df |>
ggplot(
aes(x = truth, color = truth)
) +
geom_bar()
df |>
ggplot(
aes(x = truth, fill = truth)
) +
geom_bar()
df |>
ggplot(
aes(x = truth, fill = truth)
) +
geom_bar() +
lab(
title = 'Hello'
)
df |>
ggplot(
aes(x = truth, fill = truth)
) +
geom_bar() +
labs(
title = 'Hello'
)
knitr::include_graphics("class_imbalance.png")
knitr::include_graphics("class_imbalance.png")
getwd()
p <- threshold_prediction(df, t)
p
threshold_prediction <- function(df_pred, threshold) {
pred  <- df_pred$pred_female >= threshold
reality <- df_pred$truth_bool
tp <-   sum(pred & reality)
fp <-   sum(pred & !reality)
tn <-   sum(!pred & !reality)
fn <-   sum(!pred & reality)
tib <- tibble(
threshold,
true_positive= tp,
false_positive = fp,
true_negative = tn,
false_negative = fn,
accuracy = accuracy(tp, fp, tn, fn),
precision = precision(tp, fp),
recall = recall(tp, fn),
f1 = f1(tp, fp, fn)
)
tib |>
mutate(
across(c(accuracy, precision, recall, f1), round, digits = 2)
)
}
confusion_plot <- function(x) {
cm <- tibble(
Actual = c("Positive","Positive","Negative","Negative"),
Pred   = c("Positive","Negative","Positive","Negative"),
n = c(
x$true_positive,
x$false_negative,
x$false_positive,
x$true_negative
)
)
ggplot(cm, aes(x = Pred, y = Actual, fill = n)) +
geom_tile() +
geom_text(aes(label = n), color = "white", size = 6) +
scale_fill_gradient(low = "grey70", high = "steelblue") +
labs(
title = "Confusion Matrix",
subtitle = sprintf("Threshold %.1f", t),
x = "Predicted",
y = "Actual"
) +
theme_minimal() +
theme(
plot.title = element_text(hjust = 0.5),
plot.subtitle = element_text(hjust = 0.5)
)
}
evaluate_threshold <- function(df, threshold) {
m <- threshold_prediction(df, threshold)
print(m)
confusion_plot(m)
}
threshold <- 0.2
evaluate_threshold(df, threshold)
setwd("C:/Users/ganzs/Desktop/CUNY_Github/CUNY_Assignments/607/assignment_2")
